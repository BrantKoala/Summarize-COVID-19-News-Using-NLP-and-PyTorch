{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"phase2main.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"14nFLw9HEkMEPV6X9AG-cdLAmVpO-W5Yg","authorship_tag":"ABX9TyO79v0rH9SSIzhDdLELp1Yo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import platform\n","import sys\n","\n","print(sys.version)\n","print(platform.python_version())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DeOqH1tVWX99","executionInfo":{"status":"ok","timestamp":1651475253111,"user_tz":-480,"elapsed":350,"user":{"displayName":"Chuanwang Fang","userId":"01131971792910885968"}},"outputId":"c95e0a3f-d807-46e7-9ce4-51d4d4a52f9c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["3.7.13 (default, Apr 24 2022, 01:04:09) \n","[GCC 7.5.0]\n","3.7.13\n"]}]},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/Summarize_COVID-19_News_Using_NLP_and_PyTorch/phase2\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1otawa6-Zpxa","executionInfo":{"status":"ok","timestamp":1651480075262,"user_tz":-480,"elapsed":3114,"user":{"displayName":"Chuanwang Fang","userId":"01131971792910885968"}},"outputId":"fdd9ce5b-c0a0-4d6e-d006-56eda6741765"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Dhy_Ry1SLQM","executionInfo":{"status":"ok","timestamp":1651481963300,"user_tz":-480,"elapsed":1873963,"user":{"displayName":"Chuanwang Fang","userId":"01131971792910885968"}},"outputId":"49e4b596-0999-4982-995f-878df3fec8ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading lines...\n","Read 78519 sentence pairs\n","Counting words...\n","max(length_result)=600\n","Training....\n","input_length=209\n","input_length=162\n","input_length=205\n","input_length=20\n","input_length=259\n","input_length=444\n","input_length=186\n","input_length=450\n","input_length=514\n","input_length=279\n","input_length=441\n","input_length=362\n","input_length=280\n","input_length=495\n","input_length=371\n","input_length=138\n","input_length=342\n","input_length=78\n","input_length=155\n","input_length=183\n","input_length=131\n","input_length=481\n","input_length=208\n","input_length=405\n","input_length=84\n","input_length=242\n","input_length=229\n","input_length=254\n","input_length=65\n","input_length=397\n","input_length=214\n","input_length=55\n","input_length=274\n","input_length=25\n","input_length=314\n","input_length=69\n","input_length=296\n","input_length=34\n","input_length=141\n","input_length=264\n","input_length=494\n","input_length=144\n","input_length=162\n","input_length=235\n","input_length=418\n","input_length=383\n","input_length=15\n","input_length=309\n","input_length=344\n","input_length=291\n","input_length=327\n","input_length=246\n","input_length=322\n","input_length=373\n","input_length=152\n","input_length=194\n","input_length=383\n","input_length=128\n","input_length=139\n","input_length=186\n","input_length=77\n","input_length=492\n","input_length=166\n","input_length=297\n","input_length=192\n","input_length=200\n","input_length=405\n","input_length=319\n","input_length=289\n","input_length=347\n","input_length=452\n","input_length=27\n","input_length=471\n","input_length=276\n","input_length=436\n","input_length=47\n","input_length=597\n","input_length=443\n","input_length=467\n","input_length=127\n","input_length=340\n","input_length=395\n","input_length=408\n","input_length=369\n","input_length=42\n","input_length=386\n","input_length=580\n","input_length=412\n","input_length=43\n","input_length=217\n","input_length=224\n","input_length=97\n","input_length=185\n","input_length=439\n","input_length=269\n","input_length=553\n","input_length=129\n","input_length=44\n","input_length=217\n","input_length=514\n","input_length=261\n","input_length=455\n","input_length=91\n","input_length=261\n","input_length=288\n","input_length=542\n","input_length=2\n","input_length=367\n","input_length=464\n","input_length=314\n","input_length=439\n","input_length=263\n","input_length=258\n","input_length=357\n","input_length=97\n","input_length=450\n","input_length=198\n","input_length=381\n","input_length=110\n","input_length=330\n","input_length=592\n","input_length=293\n","input_length=234\n","input_length=358\n","input_length=55\n","input_length=564\n","input_length=313\n","input_length=213\n","input_length=320\n","input_length=159\n","input_length=144\n","input_length=453\n","input_length=409\n","input_length=111\n","input_length=205\n","input_length=402\n","input_length=16\n","input_length=201\n","input_length=158\n","input_length=439\n","input_length=458\n","input_length=168\n","input_length=564\n","input_length=308\n","input_length=366\n","input_length=321\n","input_length=542\n","input_length=579\n","input_length=307\n","input_length=116\n","input_length=89\n","input_length=601\n","input_length=401\n","input_length=94\n","input_length=257\n","input_length=434\n","input_length=22\n","input_length=27\n","input_length=290\n","input_length=368\n","input_length=207\n","input_length=341\n","input_length=174\n","input_length=251\n","input_length=288\n","input_length=181\n","input_length=127\n","input_length=18\n","input_length=273\n","input_length=347\n","input_length=529\n","input_length=339\n","input_length=385\n","input_length=430\n","input_length=461\n","input_length=320\n","input_length=459\n","input_length=565\n","input_length=214\n","input_length=366\n","input_length=507\n","input_length=23\n","input_length=389\n","input_length=324\n","input_length=265\n","input_length=331\n","input_length=219\n","input_length=350\n","input_length=548\n","input_length=453\n","input_length=297\n","input_length=11\n","input_length=449\n","input_length=422\n","input_length=470\n","input_length=329\n","input_length=123\n","input_length=208\n","input_length=185\n","input_length=340\n","input_length=158\n","input_length=319\n","input_length=228\n","input_length=69\n","input_length=224\n","input_length=75\n","input_length=394\n","input_length=288\n","input_length=126\n","input_length=247\n","input_length=351\n","input_length=590\n","input_length=110\n","input_length=154\n","input_length=439\n","input_length=18\n","input_length=323\n","input_length=372\n","input_length=516\n","input_length=85\n","input_length=220\n","input_length=296\n","input_length=181\n","input_length=562\n","input_length=36\n","input_length=266\n","input_length=332\n","input_length=168\n","input_length=206\n","input_length=358\n","input_length=133\n","input_length=243\n","input_length=331\n","input_length=199\n","input_length=476\n","input_length=312\n","input_length=267\n","input_length=26\n","input_length=163\n","input_length=159\n","input_length=107\n","input_length=397\n","input_length=369\n","input_length=169\n","input_length=221\n","input_length=247\n","input_length=241\n","input_length=365\n","input_length=259\n","input_length=72\n","input_length=410\n","input_length=222\n","input_length=29\n","input_length=417\n","input_length=535\n","input_length=87\n","input_length=11\n","input_length=459\n","input_length=475\n","input_length=155\n","input_length=209\n","input_length=417\n","input_length=309\n","input_length=589\n","input_length=103\n","input_length=437\n","input_length=271\n","input_length=177\n","input_length=107\n","input_length=341\n","input_length=511\n","input_length=584\n","input_length=345\n","input_length=559\n","input_length=118\n","input_length=161\n","input_length=160\n","input_length=439\n","input_length=305\n","input_length=264\n","input_length=239\n","input_length=123\n","input_length=513\n","input_length=166\n","input_length=563\n","input_length=544\n","input_length=292\n","input_length=89\n","input_length=560\n","input_length=98\n","input_length=58\n","input_length=194\n","input_length=11\n","input_length=114\n","input_length=333\n","input_length=38\n","input_length=560\n","input_length=473\n","input_length=102\n","input_length=417\n","input_length=315\n","input_length=374\n","input_length=201\n","input_length=237\n","input_length=295\n","input_length=283\n","input_length=387\n","input_length=85\n","input_length=210\n","input_length=166\n","input_length=393\n","input_length=206\n","input_length=173\n","input_length=320\n","input_length=421\n","input_length=540\n","input_length=47\n","input_length=29\n","input_length=185\n","input_length=237\n","input_length=411\n","input_length=565\n","input_length=503\n","input_length=69\n","input_length=307\n","input_length=591\n","input_length=317\n","input_length=244\n","input_length=17\n","input_length=234\n","input_length=27\n","input_length=110\n","input_length=211\n","input_length=90\n","input_length=244\n","input_length=390\n","input_length=138\n","input_length=327\n","input_length=11\n","input_length=349\n","input_length=111\n","input_length=282\n","input_length=132\n","input_length=82\n","input_length=87\n","input_length=302\n","input_length=17\n","input_length=431\n","input_length=163\n","input_length=358\n","input_length=218\n","input_length=563\n","input_length=338\n","input_length=18\n","input_length=552\n","input_length=401\n","input_length=332\n","input_length=120\n","input_length=236\n","input_length=274\n","input_length=532\n","input_length=248\n","input_length=558\n","input_length=344\n","input_length=343\n","input_length=394\n","input_length=251\n","input_length=475\n","input_length=146\n","input_length=151\n","input_length=197\n","input_length=142\n","input_length=396\n","input_length=469\n","input_length=15\n","input_length=160\n","input_length=383\n","input_length=181\n","input_length=15\n","input_length=123\n","input_length=148\n","input_length=358\n","input_length=265\n","input_length=340\n","input_length=253\n","input_length=114\n","input_length=372\n","input_length=326\n","input_length=277\n","input_length=281\n","input_length=270\n","input_length=60\n","input_length=278\n","input_length=148\n","input_length=136\n","input_length=302\n","input_length=240\n","input_length=363\n","input_length=578\n","input_length=538\n","input_length=211\n","input_length=568\n","input_length=267\n","input_length=376\n","input_length=443\n","input_length=172\n","input_length=172\n","input_length=306\n","input_length=132\n","input_length=431\n","input_length=119\n","input_length=440\n","input_length=519\n","input_length=231\n","input_length=395\n","input_length=363\n","input_length=174\n","input_length=250\n","input_length=30\n","input_length=354\n","input_length=53\n","input_length=339\n","input_length=243\n","input_length=314\n","input_length=186\n","input_length=258\n","input_length=198\n","input_length=419\n","input_length=35\n","input_length=51\n","input_length=88\n","input_length=263\n","input_length=211\n","input_length=183\n","input_length=448\n","input_length=38\n","input_length=78\n","input_length=181\n","input_length=236\n","input_length=355\n","input_length=194\n","input_length=264\n","input_length=356\n","input_length=399\n","input_length=394\n","input_length=138\n","input_length=545\n","input_length=289\n","input_length=369\n","input_length=169\n","input_length=570\n","input_length=249\n","input_length=341\n","input_length=331\n","input_length=100\n","input_length=590\n","input_length=407\n","input_length=282\n","input_length=444\n","input_length=365\n","input_length=144\n","input_length=127\n","input_length=318\n","input_length=340\n","input_length=175\n","input_length=191\n","input_length=590\n","input_length=154\n","input_length=141\n","input_length=118\n","input_length=317\n","input_length=497\n","input_length=290\n","input_length=13\n","input_length=309\n","input_length=103\n","input_length=18\n","input_length=228\n","input_length=24\n","input_length=83\n","input_length=417\n","input_length=125\n","input_length=284\n","input_length=312\n","input_length=271\n","input_length=165\n","input_length=200\n","input_length=16\n","input_length=141\n","input_length=56\n","input_length=451\n","input_length=207\n","input_length=54\n","input_length=305\n","input_length=521\n","input_length=274\n","input_length=134\n","input_length=479\n","input_length=189\n","input_length=474\n","input_length=478\n","input_length=224\n","input_length=403\n","input_length=178\n","input_length=261\n","input_length=236\n","input_length=430\n","input_length=187\n","input_length=412\n","input_length=467\n","input_length=372\n","input_length=16\n","input_length=248\n","input_length=403\n","input_length=175\n","input_length=140\n","input_length=212\n","input_length=323\n","input_length=573\n","input_length=288\n","input_length=116\n","input_length=210\n","input_length=305\n","input_length=63\n","input_length=282\n","input_length=453\n","input_length=318\n","input_length=523\n","input_length=136\n","input_length=182\n","input_length=192\n","input_length=159\n","input_length=72\n","input_length=63\n","input_length=214\n","input_length=297\n","input_length=335\n","input_length=408\n","input_length=543\n","input_length=26\n","input_length=142\n","input_length=338\n","input_length=82\n","input_length=148\n","input_length=511\n","input_length=248\n","input_length=138\n","input_length=461\n","input_length=432\n","input_length=277\n","input_length=307\n","input_length=63\n","input_length=343\n","input_length=158\n","input_length=410\n","input_length=79\n","input_length=358\n","input_length=422\n","input_length=205\n","input_length=309\n","input_length=370\n","input_length=147\n","input_length=446\n","input_length=117\n","input_length=118\n","input_length=343\n","input_length=252\n","input_length=349\n","input_length=459\n","input_length=451\n","input_length=13\n","input_length=199\n","input_length=225\n","input_length=418\n","input_length=295\n","input_length=590\n","input_length=149\n","input_length=152\n","input_length=384\n","input_length=125\n","input_length=465\n","input_length=18\n","input_length=268\n","input_length=544\n","input_length=361\n","input_length=276\n","input_length=76\n","input_length=211\n","input_length=110\n","input_length=544\n","input_length=129\n","input_length=197\n","input_length=364\n","input_length=79\n","input_length=214\n","input_length=78\n","input_length=76\n","input_length=275\n","input_length=69\n","input_length=326\n","input_length=124\n","input_length=145\n","input_length=386\n","input_length=58\n","input_length=294\n","input_length=38\n","input_length=224\n","input_length=302\n","input_length=91\n","input_length=38\n","input_length=64\n","input_length=194\n","input_length=310\n","input_length=230\n","input_length=577\n","input_length=554\n","input_length=273\n","input_length=520\n","input_length=115\n","input_length=298\n","input_length=316\n","input_length=87\n","input_length=136\n","input_length=405\n","input_length=291\n","input_length=511\n","input_length=396\n","input_length=471\n","input_length=92\n","input_length=334\n","input_length=314\n","input_length=245\n","input_length=64\n","input_length=182\n","input_length=94\n","input_length=135\n","input_length=117\n","input_length=200\n","input_length=162\n","input_length=272\n","input_length=460\n","input_length=238\n","input_length=380\n","input_length=63\n","input_length=454\n","input_length=210\n","input_length=406\n","input_length=218\n","input_length=415\n","input_length=510\n","input_length=123\n","input_length=30\n","input_length=241\n","input_length=418\n","input_length=197\n","input_length=406\n","input_length=314\n","input_length=196\n","input_length=50\n","input_length=151\n","input_length=406\n","input_length=9\n","input_length=222\n","input_length=65\n","input_length=301\n","input_length=118\n","input_length=285\n","input_length=469\n","input_length=446\n","input_length=40\n","input_length=138\n","input_length=536\n","input_length=245\n","input_length=247\n","input_length=92\n","input_length=210\n","input_length=219\n","input_length=346\n","input_length=513\n","input_length=129\n","input_length=325\n","input_length=270\n","input_length=46\n","input_length=201\n","input_length=243\n","input_length=448\n","input_length=84\n","input_length=75\n","input_length=278\n","input_length=192\n","input_length=40\n","input_length=148\n","input_length=514\n","input_length=166\n","input_length=127\n","input_length=39\n","input_length=159\n","input_length=256\n","input_length=286\n","input_length=189\n","input_length=484\n","input_length=275\n","input_length=513\n","input_length=468\n","input_length=141\n","input_length=253\n","input_length=349\n","input_length=377\n","input_length=356\n","input_length=268\n","input_length=75\n","input_length=238\n","input_length=369\n","input_length=50\n","input_length=118\n","input_length=356\n","input_length=367\n","input_length=222\n","input_length=375\n","input_length=594\n","input_length=83\n","input_length=209\n","input_length=165\n","input_length=343\n","input_length=348\n","input_length=283\n","input_length=232\n","input_length=498\n","input_length=122\n","input_length=487\n","input_length=453\n","input_length=432\n","input_length=419\n","input_length=49\n","input_length=332\n","input_length=595\n","input_length=61\n","input_length=46\n","input_length=371\n","input_length=287\n","input_length=254\n","input_length=99\n","input_length=453\n","input_length=265\n","input_length=80\n","input_length=131\n","input_length=500\n","input_length=477\n","input_length=220\n","input_length=592\n","input_length=30\n","input_length=248\n","input_length=476\n","input_length=95\n","input_length=406\n","input_length=235\n","input_length=142\n","input_length=421\n","input_length=15\n","input_length=491\n","input_length=297\n","input_length=185\n","input_length=470\n","input_length=413\n","input_length=127\n","input_length=458\n","input_length=239\n","input_length=167\n","input_length=261\n","input_length=228\n","input_length=146\n","input_length=319\n","input_length=329\n","input_length=147\n","input_length=585\n","input_length=42\n","input_length=209\n","input_length=215\n","input_length=315\n","input_length=178\n","input_length=350\n","input_length=29\n","input_length=395\n","input_length=254\n","input_length=190\n","input_length=305\n","input_length=438\n","input_length=37\n","input_length=244\n","input_length=247\n","input_length=573\n","input_length=403\n","input_length=95\n","input_length=109\n","input_length=356\n","input_length=255\n","input_length=50\n","input_length=277\n","input_length=302\n","input_length=368\n","input_length=43\n","input_length=121\n","input_length=58\n","input_length=493\n","input_length=90\n","input_length=256\n","input_length=394\n","input_length=228\n","input_length=343\n","input_length=327\n","input_length=50\n","input_length=21\n","input_length=78\n","input_length=475\n","input_length=262\n","input_length=350\n","input_length=257\n","input_length=123\n","input_length=340\n","input_length=116\n","input_length=293\n","input_length=366\n","input_length=90\n","input_length=509\n","input_length=450\n","input_length=349\n","input_length=449\n","input_length=589\n","input_length=135\n","input_length=422\n","input_length=460\n","input_length=350\n","input_length=281\n","input_length=381\n","input_length=217\n","input_length=428\n","input_length=557\n","input_length=393\n","input_length=298\n","input_length=463\n","input_length=263\n","input_length=280\n","input_length=233\n","input_length=348\n","input_length=85\n","input_length=190\n","input_length=267\n","input_length=450\n","input_length=32\n","input_length=356\n","input_length=540\n","input_length=494\n","input_length=362\n","input_length=216\n","input_length=294\n","input_length=273\n","input_length=384\n","input_length=75\n","input_length=548\n","input_length=30\n","input_length=241\n","input_length=258\n","input_length=449\n","input_length=334\n","input_length=423\n","input_length=386\n","input_length=287\n","input_length=201\n","input_length=285\n","input_length=276\n","input_length=74\n","input_length=217\n","input_length=313\n","input_length=19\n","input_length=282\n","input_length=168\n","input_length=358\n","input_length=119\n","input_length=576\n","input_length=17\n","input_length=187\n","input_length=551\n","input_length=118\n","input_length=513\n","input_length=484\n","input_length=590\n","input_length=39\n","input_length=21\n","input_length=421\n","input_length=347\n","input_length=146\n","input_length=171\n","input_length=469\n","input_length=403\n","input_length=234\n","input_length=26\n","input_length=593\n","input_length=257\n","input_length=111\n","input_length=560\n","input_length=332\n","input_length=555\n","input_length=540\n","input_length=393\n","input_length=254\n","input_length=571\n","input_length=294\n","input_length=128\n","input_length=560\n","input_length=438\n","input_length=328\n","input_length=274\n","input_length=365\n","input_length=278\n","input_length=33\n","input_length=473\n","input_length=172\n","input_length=136\n","input_length=301\n","input_length=114\n","input_length=387\n","input_length=275\n","input_length=229\n","input_length=53\n","input_length=276\n","input_length=461\n","input_length=491\n","input_length=218\n","input_length=266\n","input_length=17\n","input_length=99\n","input_length=150\n","input_length=520\n","input_length=122\n","input_length=448\n","input_length=535\n","input_length=114\n","input_length=457\n","input_length=44\n","input_length=424\n","input_length=186\n","input_length=21\n","input_length=472\n","input_length=145\n","input_length=597\n","input_length=203\n","input_length=563\n","input_length=213\n","input_length=283\n","input_length=165\n","input_length=382\n","input_length=403\n","input_length=93\n","input_length=308\n","input_length=343\n","input_length=81\n","input_length=571\n","input_length=217\n","input_length=241\n","input_length=124\n","input_length=264\n","input_length=587\n","input_length=447\n","input_length=519\n","input_length=385\n","input_length=283\n","input_length=131\n","input_length=205\n","input_length=464\n","input_length=190\n","input_length=261\n","input_length=450\n","input_length=188\n","input_length=94\n","input_length=98\n","input_length=286\n","input_length=544\n","input_length=58\n","input_length=501\n","input_length=513\n","input_length=543\n","input_length=280\n","input_length=512\n","input_length=86\n","input_length=118\n","input_length=510\n","input_length=188\n","input_length=306\n","input_length=218\n","input_length=131\n","input_length=503\n","input_length=244\n","input_length=472\n","input_length=210\n","input_length=386\n","input_length=583\n","input_length=391\n","input_length=158\n","input_length=323\n","1000 / 1001\n","input_length=240\n"]}],"source":["from __future__ import unicode_literals, print_function, division\n","\n","import pandas as pd\n","import numpy as np\n","import json\n","import glob\n","\n","from io import open\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import random\n","import time\n","import math\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","# plt.switch_backend('agg')\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","SOS_token = 0\n","EOS_token = 1\n","MAX_LENGTH = 601\n","input_lang, output_lang, pairs = None, None, None\n","teacher_forcing_ratio = 0.5\n","\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split():\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","\n","# clean up\n","# disregard any input beyond the length\n","def select_short(dataset, target, max_len_text=600, max_len_target=30):\n","    short_text = []\n","    short_summary = []\n","    for i in range(len(dataset)):\n","        if (len(target[i].split()) <= max_len_target and len(dataset[i].split()) <= max_len_text):\n","            short_text.append(dataset[i])\n","            short_summary.append(target[i])\n","    return pd.DataFrame({'text': short_text, 'summary': short_summary})\n","\n","\n","def readData(text, summary):\n","    print(\"Reading lines...\")\n","    # Split every line into pairs and normalize\n","    pairs = [[text[i], summary[i]] for i in range(len(text))]\n","    input_lang = Lang(text)\n","    output_lang = Lang(summary)\n","    return input_lang, output_lang, pairs\n","\n","\n","def prepareData(lang1, lang2):\n","    input_lang, output_lang, pairs = readData(lang1, lang2)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    return input_lang, output_lang, pairs\n","\n","\n","def max_sequence(sequence):\n","    seq_len = []\n","    i = 1\n","    for one_seq in sequence:\n","        seq_spl = one_seq.split()\n","        seq_len.append(len(seq_spl))\n","        i = i + 1\n","    max_seq = max(seq_len)\n","    return max_seq\n","\n","\n","'''\n","Encoder是个RNN，它会遍历输入的每一个Token(词)，每个时刻的输入是上一个时刻的隐状态和输入，然后会有一个输出和新的隐状态。\n","这个新的隐状态会作为下一个时刻的输入隐状态。每个时刻都有一个输出，对于seq2seq模型来说，我们通常只保留最后一个时刻的隐状态，\n","认为它编码了整个句子的语义，但是后面我们会用到Attention机制，它还会用到Encoder每个时刻的输出。\n","Encoder处理结束后会把最后一个时刻的隐状态作为Decoder的初始隐状态。\n","'''\n","\n","'''\n","seq2seq模型常用于机器翻译，由两部分组成：encoder和decoder，一般使用RNN网络实现，比较常用的就是LSTM和GRU了。机器翻译时，\n","encoder作用是对输入句子进行特征提取，它的最后一个输出就是从这句话捕获的最后的特征。decoder就利用编码器最后的输出特征解码成目标语言。\n","Seq2Seq模型有一个缺点就是句子太长的话encoder会遗忘，那么decoder接受到的句子特征也就不完全，因此引入attention机制，\n","Decoder每次更新状态的时候都会再看一遍encoder所有状态，还会告诉decoder要更关注哪部分，这样能大大提高翻译精度。\n","具体实现就是不再单纯使用encoder的最后一个状态进行解码，在encoder工作时会保存其每一个输出和隐藏状态，\n","在解码时用于计算当前时刻隐藏状态与编码所有时刻隐藏状态的相关性。\n","'''\n","\n","\n","class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        # 继承 nn.Module 的神经网络模块在实现自己的 __init__ 函数时，一定要先调用。只有这样才能正确地初始化自定义的神经网络模块\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        # 定义一个具有input_size个单词，维度为hidden_size的查询矩阵\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        # 输入hidden_size个特征维度 隐藏是hidden_size个特征维度\n","        # 门：这里GRU的hide layer维度和embedding维度一样，但并不是必须的\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        # (seq_len, batch, hidden_size)，view实际上是对现有tensor 改造的方法\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        # 获取每个GRU的输出和隐藏状态，用于后续计算attention\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","\n","'''\n","注意力机制允许解码器针对自身输出的每一步都“关注”编码器输出的不同部分。首先需要计算一组注意力权重，\n","用来乘以编码器输出向量实现加权生成注意力向量。然后将此注意力向量与解码器当前输入进行拼接作为GRU的输入：\n","'''\n","\n","\n","class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        # 全连接层\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        # 先把输入embedding\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        # dropout防止过拟合(丢弃正则化)\n","        embedded = self.dropout(embedded)\n","        # 矩阵相乘，用注意力权重乘以编码输出\n","        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n","        # 将输入的embedding层和注意力层拼接，按维数1拼接（横着拼）\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        # 拼好后加个全连接层然后解压缩维度0。\n","        output = self.attn_combine(output).unsqueeze(0)\n","        # 激活函数\n","        output = F.relu(output)\n","        # 输入GRU\n","        output, hidden = self.gru(output, hidden)\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)\n","\n","\n","def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split()]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)\n","\n","\n","'''\n","为了训练，我们通过编码器运行输入句子，并跟踪每个输出和最新的隐藏状态。然后，解码器将令牌作为其第一个输入，\n","并将编码器的最后一个隐藏状态作为其第一个隐藏状态。<SOS>\n","\n","“教师强制”是使用真实目标输出作为每个下一个输入的概念，而不是使用解码器的猜测作为下一个输入。使用教师强制会导致它更快地收敛，\n","但是当训练有素的网络被利用时，它可能会表现出不稳定。\n","\n","你可以观察教师强迫的网络的输出，这些网络以连贯的语法阅读，但远离正确的翻译 - 直观地说，它已经学会了表示输出语法，\n","一旦老师告诉它前几个单词，它就可以“拾取”含义，但它还没有正确地学会如何从翻译中创建句子。\n","\n","由于PyTorch的自动评分给我们的自由，我们可以随机选择使用或不使用简单的if语句来强制使用教师强迫。打开以使用更多。\n","'''\n","\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion,\n","          max_length=MAX_LENGTH):\n","    # 初始化编码器的隐藏状态\n","    encoder_hidden = encoder.initHidden()\n","    # 清除渐变。Pytorch在随后的反向传播中积累梯度，因此您需要在开始训练之前清除它。否则，梯度计算将是错误的。\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    # 从相应的张量中找出输入和目标长度\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","    # 将encoder_outputs初始化为max_length大小的割炬阵列，并用零填充它。.我们将在为每个输入生成编码器输出时更新此数组。\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","    # 将损失初始化为零 。我们将在训练时更新此损失，并在后续步骤中对其运行反向传播。\n","    loss = 0\n","    print(\"input_length={}\".format(input_length))\n","    for i in range(input_length):\n","        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n","        # print(encoder_output.size())\n","        encoder_outputs[i] = encoder_output[0, 0]\n","    # 定义解码器输入和解码器隐藏状态。最初，SOS_token是句子的开头标记。\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","    # 首字母将初始化为decoder_hidden\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","    # 反向传播\n","    loss.backward()\n","    # 取编码器和解码器的梯度下降\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","    # 回波损耗\n","    return loss.item() / target_length\n","\n","\n","'''\n","整个训练过程如下所示：\n","启动计时器\n","初始化优化程序和条件\n","创建训练对集\n","启动空损耗数组进行绘图\n","然后我们多次调用，偶尔打印进度（示例百分比，到目前为止的时间，估计的时间）和平均损失。\n","'''\n","\n","\n","def trainIters(encoder, decoder, n_iters, learning_rate=0.01):\n","    print(\"Training....\")\n","    start = time.time()\n","    plot_losses = []\n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    # TODO:这里可能要改进以避免重复抽取\n","    training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n","    # plen = 0\n","    # for p in training_pairs:\n","    #     plen = max(plen, p[0].size(0))\n","    # print(\"plen={}\".format(plen))\n","    # exit(0)\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        if iter % 1000 == 0:\n","            print(iter, \"/\", n_iters + 1)\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","\n","        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","\n","def infer(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]\n","\n","\n","def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        output_words, attentions = infer(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        with open('evaluation_input.txt', 'a') as out:\n","            out.write('{}, {}\\n'.format(pair[1], output_sentence))\n","\n","\n","\n","def main():\n","    df = pd.read_csv(\"skimmed_news.csv\", encoding=\"utf-8\")\n","    global input_lang, output_lang, pairs\n","    input_lang, output_lang, pairs = prepareData(list(df['text']), list(df['summary']))\n","    length_result = []\n","    for pair in pairs:\n","        length_result.append(len(pair[0].split()))\n","    print(\"max(length_result)={}\".format(max(length_result)))\n","    # 训练\n","    hidden_size = 300\n","    encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","    attn_decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","    trainIters(encoder, attn_decoder, 1000)\n","    ENCODER_MODEL_PATH = 'encoder_model.pt'\n","    DECODER_MODEL_PATH = 'decoder_model.pt'\n","    torch.save(encoder.state_dict(), ENCODER_MODEL_PATH)\n","    torch.save(attn_decoder.state_dict(), DECODER_MODEL_PATH)\n","    evaluateRandomly(encoder, attn_decoder)\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}